{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# ipython magic to plot in line\n",
    "%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/38987/how-can-i-merge-two-python-dictionaries-in-a-single-expression\n",
    "def merge_two_dicts(x, y):\n",
    "    '''Given two dicts, merge them into a new dict as a shallow copy.'''\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Path to raw data\n",
    "out_dir    = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\Nov_2014_snow_storm_data')\n",
    "main_dir   = os.path.normpath(r'C:\\Users\\new356\\Google Drive\\Nov2014 Data QC Completed Data')\n",
    "# MetaDataFile\n",
    "meta_data_file  = os.path.join(main_dir,'CRHO_Station_lat_long_elevation.txt')\n",
    "# Ascii input folder\n",
    "#dir_in     = main_dir + '\\QC_ascii'\n",
    "dir_in     = main_dir + '\\QC_Data_ASCII_slim'\n",
    "# netcdf output folder\n",
    "dir_out    = out_dir + '\\\\QC_netcdf'\n",
    "cfileout   = os.path.join(dir_out,'CRHO.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input format of ascii files\n",
    "input_format = 'CRHO_TELM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if input_format == 'CRHO_TELM':\n",
    "    # Ascii data format info\n",
    "    c_header = 4 # Header lines\n",
    "    c_column_line = 1 # line where column names start\n",
    "    c_delimiter = ','\n",
    "    # time zone variables\n",
    "    #tz_in = pytz.timezone('Canada/Mountain')\n",
    "    tz_in = pytz.timezone('Etc/GMT-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get file in info\n",
    "#os.chdir(dir_in) # Move to input\n",
    "#content = os.listdir(os.getcwd()) # Get list of files\n",
    "#num_files = len([name for name in os.listdir('.') if os.path.isfile(name)]) # Get number of files in\n",
    "\n",
    "os.chdir(dir_in) # Move to input\n",
    "content = glob.glob('*.txt') # Get list of files\n",
    "num_files = len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in metadata (all stations)\n",
    "metadata = pd.read_csv(meta_data_file,index_col='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BNS_15min_2013_2016_slim.txt',\n",
       " 'BRP_15min_2014_2016_slim.txt',\n",
       " 'BWH_15min_2014_slim.txt',\n",
       " 'CRG_15min_2014_slim.txt',\n",
       " 'CRN_15min_2013_2016_slim.txt',\n",
       " 'FLG_15min_2014_2016_slim.txt',\n",
       " 'FRG_15min_2014_slim.txt',\n",
       " 'FRS_15min_2013_2016_slim.txt',\n",
       " 'HLN_15min_2014_2015_slim.txt',\n",
       " 'PWL_15min_2013_2016_slim.txt',\n",
       " 'PYT_15min_2013_2016_slim.txt',\n",
       " 'SIB_15min_2014_slim.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initalize stuff\n",
    "c_dict = {}\n",
    "stations_all=[]\n",
    "variables=[]\n",
    "units_all = {}\n",
    "time_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datain = pd.read_csv(content[4],header=c_column_line,dtype={'TIMESTAMP': datetime}) #,mangle_dupe_cols=False)\n",
    "#datain.drop(datain.index[:2], inplace=True)\n",
    "#datain = datain[datain.columns.drop(datain.filter(regex='.1'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datain.filter(regex='.1').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dat = ascii.read(content[4],header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names=datain.filter(regex='.1').columns)\n",
    "#datain = pd.DataFrame(dat.as_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#datain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BNS\n",
      "Processing BRP\n",
      "Processing BWH\n",
      "Processing CRG\n",
      "Processing CRN\n",
      "Processing FLG\n",
      "Processing FRG\n",
      "Processing FRS\n",
      "Processing HLN\n",
      "Processing PWL\n",
      "Processing PYT\n",
      "Processing SIB\n"
     ]
    }
   ],
   "source": [
    "# Read in each file\n",
    "for cfile in content:\n",
    "    \n",
    "    # Get current station name\n",
    "    csta_name = cfile[0:3] # Take the first three letter abbreviation as the name\n",
    "    print('Processing ' + csta_name)\n",
    "    stations_all.append(csta_name)\n",
    "    \n",
    "    # Import data to pandas dataframe\n",
    "    dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names='N/A')\n",
    "    datain = pd.DataFrame(dat.as_array())\n",
    "    \n",
    "    # Alternate method that drops duplicate (second variables) (Not correct but works for now)\n",
    "    #print(\"Using temp fix to process dataframes with duplicate columns. DATA NOT CORRECT!!!!\")\n",
    "    #datain = pd.read_csv(content[4],header=c_column_line) #,mangle_dupe_cols=False)\n",
    "    #datain.drop(datain.index[:2], inplace=True)\n",
    "    #datain = datain[datain.columns.drop(datain.filter(regex='.1'))]\n",
    "    #datain.columns\n",
    "    \n",
    "    \n",
    "    # Replace -9999 with nan (recomended by netcdf)\n",
    "    datain.replace(-9999,np.NaN,inplace=True)\n",
    "    \n",
    "    # Make TIMESTAMP the index\n",
    "    datain['TIMESTAMP'] = datain['TIMESTAMP'].astype('datetime64[ns]')\n",
    "    datain = datain.set_index('TIMESTAMP')\n",
    "    \n",
    "    # Set time zone\n",
    "    datain.index = datain.index.tz_localize(tz_in)\n",
    "    \n",
    "    # Import header info \n",
    "    headerinfo = pd.read_csv(cfile,nrows=2,skiprows=1)\n",
    "    units = headerinfo.loc[0,:].tolist() # Grab first row of dataframe (units)\n",
    "    units = units[1:] # Remove first value which is the units of the timestamp\n",
    "    units_dic = dict(zip(datain.columns,units)) # Dictionary of variable:units for this stations\n",
    "    units_all = merge_two_dicts(units_all, units_dic) # Merge dictoinaries together (units_dic overwrites any units_all)\n",
    "    \n",
    "    # Loop through all variables for this station\n",
    "    c_variables = datain.columns\n",
    "    variables.extend(c_variables.values) # Store all variables for use latter\n",
    "    for c_var in c_variables:\n",
    "        c_dict[(csta_name,c_var)]        =pd.DataFrame(datain[c_var])\n",
    "        c_dict[(csta_name,c_var)].columns=[c_var]\n",
    "        c_dict[(csta_name,c_var)].index  = datain.index\n",
    "        \n",
    "    # Save time index for each station (need to fill in missing variables later)\n",
    "    time_index[csta_name] = datain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get unique variables from list variables\n",
    "variables_uniq = set(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil Temperature C\n",
      "Soil Moisture B\n",
      "Wind Direction at A\n",
      "Incremental Precipitation B\n",
      "Soil Temperature B\n",
      "Snow Depth QC value\n",
      "Scalar Wind Speed B\n",
      "Downward Solar Radiation\n",
      "Scalar Wind Speed A\n",
      "Downward Terrestrial Rad\n",
      "Soil Temperature A\n",
      "Soil Moisture C\n",
      "Soil Moisture A\n",
      "Snow Layer Temperature A\n",
      "Soil Moisture E\n",
      "Soil Temperature D\n",
      "Soil Moisture D\n",
      "Total Pressure Adjusted to Sea-level\n",
      "Incremental Precipitation A\n",
      "Soil Heat Flux  A\n",
      "Upward Solar Radiation\n",
      "Air temperature A\n",
      "Snow Depth A\n",
      "Surface Temperature B\n",
      "Air Moisture Content A\n",
      "Upward Terrestrial Rad\n",
      "Snow Water Equivelent A\n",
      "Surface Temperature A\n",
      "Soil Temperature E\n",
      "Total Pressure Unadjusted A\n"
     ]
    }
   ],
   "source": [
    "# Extract data for each variable from the dictionary and create a xray.Dataset\n",
    "\n",
    "ds_list = [] # Initalize list of xray Datasets (each a different variable)\n",
    "\n",
    "# For each unique variable in the dictionary\n",
    "for c_var in variables_uniq:\n",
    "    print(c_var)\n",
    "    all_vars={} # Initialize dictionary that only contains one variable for all stations\n",
    "    # For each station\n",
    "    for c_sta in stations_all:\n",
    "        # Test if this varible was measured at this station\n",
    "        if ((c_sta,c_var) in c_dict):\n",
    "            all_vars[c_sta] = c_dict[(c_sta,c_var)]\n",
    "        else: # Variable doesn't exists at this station so pad it with -9999 (needed to merge into one netcdf file)\n",
    "            index_csta = time_index[c_sta]\n",
    "            df_missing = pd.DataFrame(index=index_csta, columns=[c_var])\n",
    "            #df_missing = df_missing.fillna(-9999)\n",
    "            all_vars[c_sta] = df_missing\n",
    "\n",
    "    # Concatenate each variable by stations\n",
    "    c_obs_all = pd.concat(all_vars,axis=0,keys=stations_all)\n",
    "    #c_obs_all = pd.DataFrame(c_obs_all) # not needed\n",
    "    \n",
    "    # Convert to xray and add to list\n",
    "    ds = xr.Dataset.from_dataframe(c_obs_all)\n",
    "    # Add to list and rename variables\n",
    "    ds_list.append(ds.rename({'level_0':'station','TIMESTAMP':'time'}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                               (station: 12, time: 131425)\n",
       "Coordinates:\n",
       "  * station                               (station) object 'BNS' 'BRP' 'BWH' ...\n",
       "  * time                                  (time) object 1349028000000000000 ...\n",
       "Data variables:\n",
       "    Soil Temperature C                    (station, time) float64 nan nan ...\n",
       "    Soil Moisture B                       (station, time) float64 nan nan ...\n",
       "    Wind Direction at A                   (station, time) float64 nan nan ...\n",
       "    Incremental Precipitation B           (station, time) float64 nan nan ...\n",
       "    Soil Temperature B                    (station, time) float64 nan nan ...\n",
       "    Snow Depth QC value                   (station, time) object nan nan nan ...\n",
       "    Scalar Wind Speed B                   (station, time) float64 nan nan ...\n",
       "    Downward Solar Radiation              (station, time) float64 nan nan ...\n",
       "    Scalar Wind Speed A                   (station, time) float64 nan nan ...\n",
       "    Downward Terrestrial Rad              (station, time) float64 nan nan ...\n",
       "    Soil Temperature A                    (station, time) float64 nan nan ...\n",
       "    Soil Moisture C                       (station, time) float64 nan nan ...\n",
       "    Soil Moisture A                       (station, time) float64 nan nan ...\n",
       "    Snow Layer Temperature A              (station, time) object nan nan nan ...\n",
       "    Soil Moisture E                       (station, time) float64 nan nan ...\n",
       "    Soil Temperature D                    (station, time) float64 nan nan ...\n",
       "    Soil Moisture D                       (station, time) float64 nan nan ...\n",
       "    Total Pressure Adjusted to Sea-level  (station, time) float64 nan nan ...\n",
       "    Incremental Precipitation A           (station, time) float64 nan nan ...\n",
       "    Soil Heat Flux  A                     (station, time) float64 nan nan ...\n",
       "    Upward Solar Radiation                (station, time) float64 nan nan ...\n",
       "    Air temperature A                     (station, time) float64 nan nan ...\n",
       "    Snow Depth A                          (station, time) float64 nan nan ...\n",
       "    Surface Temperature B                 (station, time) float64 nan nan ...\n",
       "    Air Moisture Content A                (station, time) float64 nan nan ...\n",
       "    Upward Terrestrial Rad                (station, time) float64 nan nan ...\n",
       "    Snow Water Equivelent A               (station, time) float64 nan nan ...\n",
       "    Surface Temperature A                 (station, time) float64 nan nan ...\n",
       "    Soil Temperature E                    (station, time) float64 nan nan ...\n",
       "    Total Pressure Unadjusted A           (station, time) float64 nan nan ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all variable Datasets using xray.update()\n",
    "ds_all = xr.Dataset()\n",
    "[ds_all.update(c_ds) for c_ds in ds_list]\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add variable attributes (units), and fix variable names (remove spaces)\n",
    "for cvar in ds_all.data_vars:\n",
    "    # add units as attributes\n",
    "    ds_all.get(cvar).attrs['unit']   = units_all[cvar]\n",
    "    # Remove spaces in variable names\n",
    "    ds_all.rename({cvar:cvar.replace(\" \",\"\")},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tell xray TIMESTAMP is a datetime (it forgets for some reason)\n",
    "ds_all['time'] = pd.to_datetime(ds_all.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure it is written in correct local time zone (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elevation(m)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNS</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PWL</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRS</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRN</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRP</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLG</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYT</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWH</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRG</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRG</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIB</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLN</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat   long   elevation(m)\n",
       "station                            \n",
       "BNS        99     99           2099\n",
       "PWL        99     99           2100\n",
       "FRS        99     99           2330\n",
       "CRN        99     99           2205\n",
       "BRP        99     99           9999\n",
       "FLG        99     99           9999\n",
       "PYT        99     99           9999\n",
       "BWH        99     99           9999\n",
       "CRG        99     99           9999\n",
       "FRG        99     99           9999\n",
       "SIB        99     99           9999\n",
       "HLN        99     99           9999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add meta data for each station\n",
    "ds_all = ds_all.merge({'Elevation': ('station',metadata[' elevation(m)'])})\n",
    "ds_all = ds_all.merge({'Lat': ('station',metadata[' lat'])})\n",
    "ds_all = ds_all.merge({'Lon': ('station',metadata[' long'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                           (station: 12, time: 131425)\n",
       "Coordinates:\n",
       "  * station                           (station) object 'BNS' 'BRP' 'BWH' ...\n",
       "  * time                              (time) datetime64[ns] 2012-09-30T18:00:00 ...\n",
       "    Elevation                         (station) int64 2099 2100 2330 2205 ...\n",
       "    Lat                               (station) int64 99 99 99 99 99 99 99 ...\n",
       "    Lon                               (station) int64 99 99 99 99 99 99 99 ...\n",
       "Data variables:\n",
       "    SoilTemperatureC                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureB                     (station, time) float64 nan nan nan ...\n",
       "    WindDirectionatA                  (station, time) float64 nan nan nan ...\n",
       "    IncrementalPrecipitationB         (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureB                  (station, time) float64 nan nan nan ...\n",
       "    SnowDepthQCvalue                  (station, time) object nan nan nan nan ...\n",
       "    ScalarWindSpeedB                  (station, time) float64 nan nan nan ...\n",
       "    DownwardSolarRadiation            (station, time) float64 nan nan nan ...\n",
       "    ScalarWindSpeedA                  (station, time) float64 nan nan nan ...\n",
       "    DownwardTerrestrialRad            (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureA                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureC                     (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureA                     (station, time) float64 nan nan nan ...\n",
       "    SnowLayerTemperatureA             (station, time) object nan nan nan nan ...\n",
       "    SoilMoistureE                     (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureD                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureD                     (station, time) float64 nan nan nan ...\n",
       "    TotalPressureAdjustedtoSea-level  (station, time) float64 nan nan nan ...\n",
       "    IncrementalPrecipitationA         (station, time) float64 nan nan nan ...\n",
       "    SoilHeatFluxA                     (station, time) float64 nan nan nan ...\n",
       "    UpwardSolarRadiation              (station, time) float64 nan nan nan ...\n",
       "    AirtemperatureA                   (station, time) float64 nan nan nan ...\n",
       "    SnowDepthA                        (station, time) float64 nan nan nan ...\n",
       "    SurfaceTemperatureB               (station, time) float64 nan nan nan ...\n",
       "    AirMoistureContentA               (station, time) float64 nan nan nan ...\n",
       "    UpwardTerrestrialRad              (station, time) float64 nan nan nan ...\n",
       "    SnowWaterEquivelentA              (station, time) float64 nan nan nan ...\n",
       "    SurfaceTemperatureA               (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureE                  (station, time) float64 nan nan nan ...\n",
       "    TotalPressureUnadjustedA          (station, time) float64 nan nan nan ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make meta data coordiates from variables\n",
    "ds_all.set_coords(['Elevation','Lat','Lon'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export to netcdf\n",
    "ds_all.to_netcdf(cfileout,format='netcdf4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
