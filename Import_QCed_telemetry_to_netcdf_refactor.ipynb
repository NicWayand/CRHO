{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# ipython magic to plot in line\n",
    "%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/38987/how-can-i-merge-two-python-dictionaries-in-a-single-expression\n",
    "def merge_two_dicts(x, y):\n",
    "    '''Given two dicts, merge them into a new dict as a shallow copy.'''\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Path to raw data\n",
    "main_dir   = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\Nov_2014_snow_storm_data')\n",
    "# Ascii input folder\n",
    "dir_in     = main_dir + '\\QC_ascii'\n",
    "# netcdf output folder\n",
    "dir_out    = main_dir + '\\\\QC_netcdf'\n",
    "cfileout   = os.path.join(dir_out,'CRHO.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input format of ascii files\n",
    "input_format = 'CRHO_TELM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if input_format == 'CRHO_TELM':\n",
    "    # Ascii data format info\n",
    "    c_header = 4 # Header lines\n",
    "    c_column_line = 1 # line where column names start\n",
    "    c_delimiter = ','\n",
    "    # time zone variables\n",
    "    #tz_in = pytz.timezone('Canada/Mountain')\n",
    "    tz_in = pytz.timezone('Etc/GMT-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get file in info\n",
    "os.chdir(dir_in) # Move to input\n",
    "content = os.listdir(os.getcwd()) # Get list of files\n",
    "num_files = len([name for name in os.listdir('.') if os.path.isfile(name)]) # Get number of files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initalize stuff\n",
    "c_dict = {}\n",
    "stations_all=[]\n",
    "variables=[]\n",
    "units_all = {}\n",
    "time_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BNS\n",
      "Processing CRN\n",
      "Processing FRS\n",
      "Processing PWL\n"
     ]
    }
   ],
   "source": [
    "# Read in each file\n",
    "for cfile in content:\n",
    "    # Get current station name\n",
    "    csta_name = cfile[0:3] # Take the first three letter abbreviation as the name\n",
    "    print('Processing ' + csta_name)\n",
    "    stations_all.append(csta_name)\n",
    "    # Import data to pandas dataframe\n",
    "    dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names='N/A')\n",
    "    datain = pd.DataFrame(dat.as_array())\n",
    "    \n",
    "    # Replace -9999 with nan (recomended by netcdf)\n",
    "    datain.replace(-9999,np.NaN,inplace=True)\n",
    "    \n",
    "    # Make TIMESTAMP the index\n",
    "    datain['TIMESTAMP'] = datain['TIMESTAMP'].astype('datetime64[ns]')\n",
    "    datain = datain.set_index('TIMESTAMP')\n",
    "    \n",
    "    # Set time zone\n",
    "    datain.index = datain.index.tz_localize(tz_in)\n",
    "    \n",
    "    # Import header info \n",
    "    headerinfo = pd.read_csv(cfile,nrows=2,skiprows=1)\n",
    "    units = headerinfo.loc[0,:].tolist() # Grab first row of dataframe (units)\n",
    "    units = units[1:] # Remove first value which is the units of the timestamp\n",
    "    units_dic = dict(zip(datain.columns,units)) # Dictionary of variable:units for this stations\n",
    "    units_all = merge_two_dicts(units_all, units_dic) # Merge dictoinaries together (units_dic overwrites any units_all)\n",
    "    \n",
    "    # Loop through all variables for this station\n",
    "    c_variables = datain.columns\n",
    "    variables.extend(c_variables.values) # Store all variables for use latter\n",
    "    for c_var in c_variables:\n",
    "        c_dict[(csta_name,c_var)]        =pd.DataFrame(datain[c_var])\n",
    "        c_dict[(csta_name,c_var)].columns=[c_var]\n",
    "        c_dict[(csta_name,c_var)].index  = datain.index\n",
    "        \n",
    "    # Save time index for each station (need to fill in missing variables later)\n",
    "    time_index[csta_name] = datain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get unique variables from list variables\n",
    "variables_uniq = set(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow Water Equivelent A\n",
      "Net Radiation\n",
      "Total Pressure unadjusted A\n",
      "Total Pressure adjusted to sea-level\n",
      "Soil Temperature C\n",
      "Incremental Precipitation A\n",
      "Soil Temperature D\n",
      "Air Moisture Content A\n",
      "Soil Temperature B\n",
      "Incremental Precipitation B\n",
      "Soil Temperature A\n",
      "Albedo\n",
      "Scalar Wind Speed A\n",
      "Soil Moisture A\n",
      "Upward Solar Radiation\n",
      "Downward Solar Radiation\n",
      "Air temperature A\n",
      "Upward Terrestrial Rad\n",
      "Snow Depth QC value\n",
      "Soil Temperature E\n",
      "Soil Moisture C\n",
      "Scalar Wind Speed B\n",
      "Soil Heat Flux  A\n",
      "Wind Direction at A\n",
      "Soil Moisture E\n",
      "Soil Moisture B\n",
      "Downward Terrestrial Rad\n",
      "Snow Depth A\n",
      "Soil Moisture D\n"
     ]
    }
   ],
   "source": [
    "# Extract data for each variable from the dictionary and create a xray.Dataset\n",
    "\n",
    "ds_list = [] # Initalize list of xray Datasets (each a different variable)\n",
    "\n",
    "# For each unique variable in the dictionary\n",
    "for c_var in variables_uniq:\n",
    "    print(c_var)\n",
    "    all_vars={} # Initialize dictionary that only contains one variable for all stations\n",
    "    # For each station\n",
    "    for c_sta in stations_all:\n",
    "        # Test if this varible was measured at this station\n",
    "        if ((c_sta,c_var) in c_dict):\n",
    "            all_vars[c_sta] = c_dict[(c_sta,c_var)]\n",
    "        else: # Variable doesn't exists at this station so pad it with -9999 (needed to merge into one netcdf file)\n",
    "            index_csta = time_index[c_sta]\n",
    "            df_missing = pd.DataFrame(index=index_csta, columns=[c_var])\n",
    "            #df_missing = df_missing.fillna(-9999)\n",
    "            all_vars[c_sta] = df_missing\n",
    "\n",
    "    # Concatenate each variable by stations\n",
    "    c_obs_all = pd.concat(all_vars,axis=0,keys=stations_all)\n",
    "    #c_obs_all = pd.DataFrame(c_obs_all) # not needed\n",
    "    \n",
    "    # Convert to xray and add to list\n",
    "    ds = xr.Dataset.from_dataframe(c_obs_all)\n",
    "    # Add to list and rename variables\n",
    "    ds_list.append(ds.rename({'level_0':'station','TIMESTAMP':'time'}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                               (station: 4, time: 131425)\n",
       "Coordinates:\n",
       "  * station                               (station) object 'BNS' 'CRN' 'FRS' ...\n",
       "  * time                                  (time) object 1349028000000000000 ...\n",
       "Data variables:\n",
       "    Snow Water Equivelent A               (station, time) float64 nan nan ...\n",
       "    Net Radiation                         (station, time) float64 nan nan ...\n",
       "    Total Pressure unadjusted A           (station, time) float64 nan nan ...\n",
       "    Total Pressure adjusted to sea-level  (station, time) float64 nan nan ...\n",
       "    Soil Temperature C                    (station, time) float64 nan nan ...\n",
       "    Incremental Precipitation A           (station, time) float64 nan nan ...\n",
       "    Soil Temperature D                    (station, time) float64 nan nan ...\n",
       "    Air Moisture Content A                (station, time) float64 nan nan ...\n",
       "    Soil Temperature B                    (station, time) float64 nan nan ...\n",
       "    Incremental Precipitation B           (station, time) float64 nan nan ...\n",
       "    Soil Temperature A                    (station, time) float64 nan nan ...\n",
       "    Albedo                                (station, time) float64 nan nan ...\n",
       "    Scalar Wind Speed A                   (station, time) float64 nan nan ...\n",
       "    Soil Moisture A                       (station, time) float64 nan nan ...\n",
       "    Upward Solar Radiation                (station, time) float64 nan nan ...\n",
       "    Downward Solar Radiation              (station, time) float64 nan nan ...\n",
       "    Air temperature A                     (station, time) float64 nan nan ...\n",
       "    Upward Terrestrial Rad                (station, time) float64 nan nan ...\n",
       "    Snow Depth QC value                   (station, time) float64 nan nan ...\n",
       "    Soil Temperature E                    (station, time) float64 nan nan ...\n",
       "    Soil Moisture C                       (station, time) float64 nan nan ...\n",
       "    Scalar Wind Speed B                   (station, time) float64 nan nan ...\n",
       "    Soil Heat Flux  A                     (station, time) float64 nan nan ...\n",
       "    Wind Direction at A                   (station, time) float64 nan nan ...\n",
       "    Soil Moisture E                       (station, time) float64 nan nan ...\n",
       "    Soil Moisture B                       (station, time) float64 nan nan ...\n",
       "    Downward Terrestrial Rad              (station, time) float64 nan nan ...\n",
       "    Snow Depth A                          (station, time) float64 nan nan ...\n",
       "    Soil Moisture D                       (station, time) float64 nan nan ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all variable Datasets using xray.update()\n",
    "ds_all = xr.Dataset()\n",
    "[ds_all.update(c_ds) for c_ds in ds_list]\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add variable attributes (units), and fix variable names (remove spaces)\n",
    "for cvar in ds_all.data_vars:\n",
    "    # add units as attributes\n",
    "    ds_all.get(cvar).attrs['unit']   = units_all[cvar]\n",
    "    # Remove spaces in variable names\n",
    "    ds_all.rename({cvar:cvar.replace(\" \",\"\")},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tell xray TIMESTAMP is a datetime (it forgets for some reason)\n",
    "ds_all['time'] = pd.to_datetime(ds_all.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                           (station: 4, time: 131425)\n",
       "Coordinates:\n",
       "  * station                           (station) object 'BNS' 'CRN' 'FRS' 'PWL'\n",
       "  * time                              (time) datetime64[ns] 2012-09-30T18:00:00 ...\n",
       "Data variables:\n",
       "    SnowWaterEquivelentA              (station, time) float64 nan nan nan ...\n",
       "    NetRadiation                      (station, time) float64 nan nan nan ...\n",
       "    TotalPressureunadjustedA          (station, time) float64 nan nan nan ...\n",
       "    TotalPressureadjustedtosea-level  (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureC                  (station, time) float64 nan nan nan ...\n",
       "    IncrementalPrecipitationA         (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureD                  (station, time) float64 nan nan nan ...\n",
       "    AirMoistureContentA               (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureB                  (station, time) float64 nan nan nan ...\n",
       "    IncrementalPrecipitationB         (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureA                  (station, time) float64 nan nan nan ...\n",
       "    Albedo                            (station, time) float64 nan nan nan ...\n",
       "    ScalarWindSpeedA                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureA                     (station, time) float64 nan nan nan ...\n",
       "    UpwardSolarRadiation              (station, time) float64 nan nan nan ...\n",
       "    DownwardSolarRadiation            (station, time) float64 nan nan nan ...\n",
       "    AirtemperatureA                   (station, time) float64 nan nan nan ...\n",
       "    UpwardTerrestrialRad              (station, time) float64 nan nan nan ...\n",
       "    SnowDepthQCvalue                  (station, time) float64 nan nan nan ...\n",
       "    SoilTemperatureE                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureC                     (station, time) float64 nan nan nan ...\n",
       "    ScalarWindSpeedB                  (station, time) float64 nan nan nan ...\n",
       "    SoilHeatFluxA                     (station, time) float64 nan nan nan ...\n",
       "    WindDirectionatA                  (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureE                     (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureB                     (station, time) float64 nan nan nan ...\n",
       "    DownwardTerrestrialRad            (station, time) float64 nan nan nan ...\n",
       "    SnowDepthA                        (station, time) float64 nan nan nan ...\n",
       "    SoilMoistureD                     (station, time) float64 nan nan nan ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export to netcdf\n",
    "ds_all.to_netcdf(cfileout,format='netcdf4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
