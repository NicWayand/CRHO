{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# ipython magic to plot in line\n",
    "%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Path to raw data\n",
    "main_dir   = os.path.normpath('F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\CRHO_Sites\\Raw')\n",
    "#main_dir   = os.path.normpath('C:\\Users\\new356\\Google') # Drive\\Postdoc_Research\\Data\\CRHO_Sites\\Raw')\n",
    "# Ascii input folder\n",
    "dir_in     = main_dir + '\\ASCII'\n",
    "# netcdf output folder\n",
    "dir_out = main_dir + '\\\\netcdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input format of ascii files\n",
    "input_format = 'CRHO_TELM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if input_format == 'CRHO_TELM':\n",
    "    # Ascii data format info\n",
    "    c_header = 4 # Header lines\n",
    "    c_column_line = 1 # line where column names start\n",
    "    c_delimiter = ','\n",
    "    # time zone variables\n",
    "    #tz_in = pytz.timezone('Canada/Mountain')\n",
    "    tz_in = pytz.timezone('Etc/GMT-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get file in info\n",
    "os.chdir(dir_in) # Move to input\n",
    "content = os.listdir(os.getcwd()) # Get list of files\n",
    "num_files = len([name for name in os.listdir('.') if os.path.isfile(name)]) # Get number of files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BNS\n",
      "need to get correct site location info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\new356\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:34: FutureWarning: the `dim` argument to `concat` will be required in a future version of xarray; for now, setting it to the old default of 'concat_dim'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate xarray Dataset and DataArray objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-803faee78b3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Add Coords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'need to get correct site location info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'LAT'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'site'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m39.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;31m#ds.coords['LAT'] = 39.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LON'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m120.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\xarray\\core\\combine.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, dim, data_vars, coords, compat, positions, indexers, mode, concat_over)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dataset_concat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         raise TypeError('can only concatenate xarray Dataset and DataArray '\n\u001b[0m\u001b[0;32m    113\u001b[0m                         'objects')\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate xarray Dataset and DataArray objects"
     ]
    }
   ],
   "source": [
    "# Read in each file\n",
    "ds_ALL = []\n",
    "for cfile in content:\n",
    "    # Get current station name\n",
    "    csta_name = cfile[0:3] # Take the first three letter abbreviation as the name\n",
    "    print('Processing ' + csta_name)\n",
    "    \n",
    "    # Import data to pandas dataframe\n",
    "    dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter)\n",
    "    datain = pd.DataFrame(dat.as_array())\n",
    "    \n",
    "    # Make TIMESTAMP the index\n",
    "    datain['TIMESTAMP'] = datain['TIMESTAMP'].astype('datetime64[ns]')\n",
    "    datain = datain.set_index('TIMESTAMP')\n",
    "    \n",
    "    # Set time zone\n",
    "    datain.index = datain.index.tz_localize(tz_in)\n",
    "    \n",
    "    # Import header info\n",
    "    headerinfo = pd.read_csv(cfile,nrows=2,skiprows=1)\n",
    "    \n",
    "    # Convert to xray\n",
    "    ds = xr.Dataset.from_dataframe(datain)\n",
    "    \n",
    "    # Rename time\n",
    "    ds.rename({'TIMESTAMP':'time'},inplace=True)\n",
    "    \n",
    "    # Add new site dimension and make record\n",
    "    ds = xr.concat([ds],'site',data_vars='all')\n",
    "    #ds_site['site'] = csta_name\n",
    "\n",
    "    # Add Coords\n",
    "    print('need to get correct site location info, make these variables')\n",
    "    #c_LAT xr.DataArray(39.0,['site',0])\n",
    "    #ds = xr.concat({'LAT':('site',[39.0])})\n",
    "    ds.coords['LAT'] = 39.0\n",
    "    ds.coords['LON'] = -120.0\n",
    "    #ds.coords['sta_name'] = csta_name\n",
    "    \n",
    "    # Add variable attributes (units and sample period)\n",
    "    for cvar in ds.data_vars:\n",
    "        ds.get(cvar).attrs['unit']   = headerinfo.loc[0,[cvar]].values[0]\n",
    "        ds.get(cvar).attrs['sample'] = headerinfo.loc[1,[cvar]].values[0]\n",
    "        \n",
    "    # Change variable names to CF format?\n",
    "    \n",
    "    # Export to netcdf\n",
    "    cfileout = os.path.join(dir_out,csta_name + '.nc')\n",
    "    ds.to_netcdf(cfileout,format='netcdf4') #,encoding={'AirTemp_Avg': {'dtype': 'int16', 'scale_factor': 0.1, '_FillValue': -9999}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-09-01 20:15:00+06:00', '2015-09-01 20:30:00+06:00',\n",
       "               '2015-09-01 20:45:00+06:00', '2015-09-01 21:00:00+06:00',\n",
       "               '2015-09-01 21:15:00+06:00', '2015-09-01 21:30:00+06:00',\n",
       "               '2015-09-01 21:45:00+06:00', '2015-09-01 22:00:00+06:00',\n",
       "               '2015-09-01 22:15:00+06:00', '2015-09-01 22:30:00+06:00',\n",
       "               ...\n",
       "               '2016-05-13 16:45:00+06:00', '2016-05-13 17:00:00+06:00',\n",
       "               '2016-05-13 17:15:00+06:00', '2016-05-13 17:30:00+06:00',\n",
       "               '2016-05-13 17:45:00+06:00', '2016-05-13 18:00:00+06:00',\n",
       "               '2016-05-13 18:15:00+06:00', '2016-05-13 18:30:00+06:00',\n",
       "               '2016-05-13 18:45:00+06:00', '2016-05-13 19:00:00+06:00'],\n",
       "              dtype='datetime64[ns, Etc/GMT-6]', name='TIMESTAMP', length=24474, freq=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open and combine multiple files\n",
    "#os.chdir(dir_out)\n",
    "#ds_ALL = xr.open_mfdataset('BNS.nc',chunks=10,concat_dim='Site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
