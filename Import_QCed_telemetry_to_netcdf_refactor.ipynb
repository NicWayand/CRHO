{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# ipython magic to plot in line\n",
    "%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/38987/how-can-i-merge-two-python-dictionaries-in-a-single-expression\n",
    "def merge_two_dicts(x, y):\n",
    "    '''Given two dicts, merge them into a new dict as a shallow copy.'''\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Path to raw data\n",
    "main_dir   = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\Nov_2014_snow_storm_data')\n",
    "# MetaDataFile\n",
    "meta_data_file  = os.path.join(main_dir,'CRHO_Station_lat_long_elevation.txt')\n",
    "# Ascii input folder\n",
    "dir_in     = main_dir + '\\QC_ascii'\n",
    "# netcdf output folder\n",
    "dir_out    = main_dir + '\\\\QC_netcdf'\n",
    "cfileout   = os.path.join(dir_out,'CRHO.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input format of ascii files\n",
    "input_format = 'CRHO_TELM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if input_format == 'CRHO_TELM':\n",
    "    # Ascii data format info\n",
    "    c_header = 4 # Header lines\n",
    "    c_column_line = 1 # line where column names start\n",
    "    c_delimiter = ','\n",
    "    # time zone variables\n",
    "    #tz_in = pytz.timezone('Canada/Mountain')\n",
    "    tz_in = pytz.timezone('Etc/GMT-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get file in info\n",
    "os.chdir(dir_in) # Move to input\n",
    "content = os.listdir(os.getcwd()) # Get list of files\n",
    "num_files = len([name for name in os.listdir('.') if os.path.isfile(name)]) # Get number of files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in metadata (all stations)\n",
    "metadata = pd.read_csv(meta_data_file,index_col='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>elevation(m)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNS</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PWL</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRS</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRN</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat   long   elevation(m)\n",
       "station                            \n",
       "BNS        99     99           2099\n",
       "PWL        99     99           2100\n",
       "FRS        99     99           2330\n",
       "CRN        99     99           2205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initalize stuff\n",
    "c_dict = {}\n",
    "stations_all=[]\n",
    "variables=[]\n",
    "units_all = {}\n",
    "time_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BNS\n",
      "Processing BRP\n"
     ]
    },
    {
     "ename": "InconsistentTableError",
     "evalue": "\nERROR: Unable to guess table format with the guesses listed below:\nReader:Ecsv data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FixedWidthTwoLine data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Rdb data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastTab data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Tab data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Cds data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Daophot data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:SExtractor data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Ipac data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Latex data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:AASTex data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastCommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastCommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:CommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:CommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:FastNoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastNoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:NoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:NoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1\n\n************************************************************************\n** ERROR: Unable to guess table format with the guesses listed above. **\n**                                                                    **\n** To figure out why the table did not read, use guess=False and      **\n** appropriate arguments to read().  In particular specify the format **\n** and any known attributes like the delimiter.                       **\n************************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\io\\ascii\\ui.py\u001b[0m in \u001b[0;36m_guess\u001b[1;34m(table, read_kwargs, format, fast_reader)\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mread_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m             _read_trace.append({'kwargs': read_kwargs,\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\io\\ascii\\core.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, table)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'table_meta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\io\\ascii\\core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, cols, meta)\u001b[0m\n\u001b[0;32m    967\u001b[0m         out = Table([x.data for x in cols], names=[x.name for x in cols], masked=masked,\n\u001b[1;32m--> 968\u001b[1;33m                     meta=meta['table'])\n\u001b[0m\u001b[0;32m    969\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_col\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\table\\table.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, masked, names, dtype, meta, copy, rows, copy_indices)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Finally do the real initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\table\\table.py\u001b[0m in \u001b[0;36m_init_from_list\u001b[1;34m(self, data, names, dtype, n_cols, copy)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\table\\table.py\u001b[0m in \u001b[0;36m_init_from_cols\u001b[1;34m(self, cols)\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0mnewcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_col_for_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_table_from_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\table\\table.py\u001b[0m in \u001b[0;36m_make_table_from_cols\u001b[1;34m(table, cols)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Duplicate column names'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Duplicate column names",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInconsistentTableError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-20db7120e42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstations_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsta_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Import data to pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mascii\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_column_line\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_delimiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexclude_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'N/A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdatain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\io\\ascii\\ui.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(table, guess, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;31m# through below to the non-guess way so that any problems result in a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# more useful traceback.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_guess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_reader_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mguess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\new356\\Anaconda3\\lib\\site-packages\\astropy\\io\\ascii\\ui.py\u001b[0m in \u001b[0;36m_guess\u001b[1;34m(table, read_kwargs, format, fast_reader)\u001b[0m\n\u001b[0;32m    492\u001b[0m                    '************************************************************************']\n\u001b[0;32m    493\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInconsistentTableError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_guess_kwargs_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInconsistentTableError\u001b[0m: \nERROR: Unable to guess table format with the guesses listed below:\nReader:Ecsv data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FixedWidthTwoLine data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Rdb data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastTab data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Tab data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Cds data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Daophot data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:SExtractor data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Ipac data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:Latex data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:AASTex data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 strict_names: True\nReader:FastCommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastCommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:CommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:CommentedHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastBasic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:FastNoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:FastNoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:NoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: '\"' strict_names: True\nReader:NoHeader data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1 quotechar: \"'\" strict_names: True\nReader:Basic data_start: 4 delimiter: ',' exclude_names: 'N/A' fill_values: [('', '0')] header_start: 1\n\n************************************************************************\n** ERROR: Unable to guess table format with the guesses listed above. **\n**                                                                    **\n** To figure out why the table did not read, use guess=False and      **\n** appropriate arguments to read().  In particular specify the format **\n** and any known attributes like the delimiter.                       **\n************************************************************************"
     ]
    }
   ],
   "source": [
    "# Read in each file\n",
    "for cfile in content:\n",
    "    # Get current station name\n",
    "    csta_name = cfile[0:3] # Take the first three letter abbreviation as the name\n",
    "    print('Processing ' + csta_name)\n",
    "    stations_all.append(csta_name)\n",
    "    # Import data to pandas dataframe\n",
    "    dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names='N/A')\n",
    "    datain = pd.DataFrame(dat.as_array())\n",
    "    \n",
    "    # Replace -9999 with nan (recomended by netcdf)\n",
    "    datain.replace(-9999,np.NaN,inplace=True)\n",
    "    \n",
    "    # Make TIMESTAMP the index\n",
    "    datain['TIMESTAMP'] = datain['TIMESTAMP'].astype('datetime64[ns]')\n",
    "    datain = datain.set_index('TIMESTAMP')\n",
    "    \n",
    "    # Set time zone\n",
    "    datain.index = datain.index.tz_localize(tz_in)\n",
    "    \n",
    "    # Import header info \n",
    "    headerinfo = pd.read_csv(cfile,nrows=2,skiprows=1)\n",
    "    units = headerinfo.loc[0,:].tolist() # Grab first row of dataframe (units)\n",
    "    units = units[1:] # Remove first value which is the units of the timestamp\n",
    "    units_dic = dict(zip(datain.columns,units)) # Dictionary of variable:units for this stations\n",
    "    units_all = merge_two_dicts(units_all, units_dic) # Merge dictoinaries together (units_dic overwrites any units_all)\n",
    "    \n",
    "    # Loop through all variables for this station\n",
    "    c_variables = datain.columns\n",
    "    variables.extend(c_variables.values) # Store all variables for use latter\n",
    "    for c_var in c_variables:\n",
    "        c_dict[(csta_name,c_var)]        =pd.DataFrame(datain[c_var])\n",
    "        c_dict[(csta_name,c_var)].columns=[c_var]\n",
    "        c_dict[(csta_name,c_var)].index  = datain.index\n",
    "        \n",
    "    # Save time index for each station (need to fill in missing variables later)\n",
    "    time_index[csta_name] = datain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get unique variables from list variables\n",
    "variables_uniq = set(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract data for each variable from the dictionary and create a xray.Dataset\n",
    "\n",
    "ds_list = [] # Initalize list of xray Datasets (each a different variable)\n",
    "\n",
    "# For each unique variable in the dictionary\n",
    "for c_var in variables_uniq:\n",
    "    print(c_var)\n",
    "    all_vars={} # Initialize dictionary that only contains one variable for all stations\n",
    "    # For each station\n",
    "    for c_sta in stations_all:\n",
    "        # Test if this varible was measured at this station\n",
    "        if ((c_sta,c_var) in c_dict):\n",
    "            all_vars[c_sta] = c_dict[(c_sta,c_var)]\n",
    "        else: # Variable doesn't exists at this station so pad it with -9999 (needed to merge into one netcdf file)\n",
    "            index_csta = time_index[c_sta]\n",
    "            df_missing = pd.DataFrame(index=index_csta, columns=[c_var])\n",
    "            #df_missing = df_missing.fillna(-9999)\n",
    "            all_vars[c_sta] = df_missing\n",
    "\n",
    "    # Concatenate each variable by stations\n",
    "    c_obs_all = pd.concat(all_vars,axis=0,keys=stations_all)\n",
    "    #c_obs_all = pd.DataFrame(c_obs_all) # not needed\n",
    "    \n",
    "    # Convert to xray and add to list\n",
    "    ds = xr.Dataset.from_dataframe(c_obs_all)\n",
    "    # Add to list and rename variables\n",
    "    ds_list.append(ds.rename({'level_0':'station','TIMESTAMP':'time'}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all variable Datasets using xray.update()\n",
    "ds_all = xr.Dataset()\n",
    "[ds_all.update(c_ds) for c_ds in ds_list]\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add variable attributes (units), and fix variable names (remove spaces)\n",
    "for cvar in ds_all.data_vars:\n",
    "    # add units as attributes\n",
    "    ds_all.get(cvar).attrs['unit']   = units_all[cvar]\n",
    "    # Remove spaces in variable names\n",
    "    ds_all.rename({cvar:cvar.replace(\" \",\"\")},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tell xray TIMESTAMP is a datetime (it forgets for some reason)\n",
    "ds_all['time'] = pd.to_datetime(ds_all.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add meta data for each station\n",
    "ds_all = ds_all.merge({'Elevation': ('station',metadata[' elevation(m)'])})\n",
    "ds_all = ds_all.merge({'Lat': ('station',metadata[' lat'])})\n",
    "ds_all = ds_all.merge({'Lon': ('station',metadata[' long'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export to netcdf\n",
    "ds_all.to_netcdf(cfileout,format='netcdf4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
