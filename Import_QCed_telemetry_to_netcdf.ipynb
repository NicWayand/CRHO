{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# ipython magic to plot in line\n",
    "%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from astropy.io import ascii\n",
    "import pytz\n",
    "# OS interaction\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Path to raw data\n",
    "main_dir   = os.path.normpath(r'F:\\Work\\e\\Data\\Obs\\Canada_Project_Sites\\Nov_2014_snow_storm_data')\n",
    "# Ascii input folder\n",
    "dir_in     = main_dir + '\\QC_ascii'\n",
    "# netcdf output folder\n",
    "dir_out    = main_dir + '\\\\QC_netcdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input format of ascii files\n",
    "input_format = 'CRHO_TELM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if input_format == 'CRHO_TELM':\n",
    "    # Ascii data format info\n",
    "    c_header = 4 # Header lines\n",
    "    c_column_line = 1 # line where column names start\n",
    "    c_delimiter = ','\n",
    "    # time zone variables\n",
    "    #tz_in = pytz.timezone('Canada/Mountain')\n",
    "    tz_in = pytz.timezone('Etc/GMT-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get file in info\n",
    "os.chdir(dir_in) # Move to input\n",
    "content = os.listdir(os.getcwd()) # Get list of files\n",
    "num_files = len([name for name in os.listdir('.') if os.path.isfile(name)]) # Get number of files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names='N/A',guess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BNS\n",
      "need to get correct site location info, make these variables\n",
      "Frozen(SortedKeysDict({'site': 1, 'time': 50980}))\n",
      "Processing CRN\n",
      "need to get correct site location info, make these variables\n",
      "Frozen(SortedKeysDict({'site': 1, 'time': 50980}))\n",
      "Processing FRS\n",
      "need to get correct site location info, make these variables\n",
      "Frozen(SortedKeysDict({'site': 1, 'time': 50980}))\n",
      "Processing PWL\n",
      "need to get correct site location info, make these variables\n",
      "Frozen(SortedKeysDict({'site': 1, 'time': 50980}))\n"
     ]
    }
   ],
   "source": [
    "# Read in each file\n",
    "ds_ALL = []\n",
    "for cfile in content:\n",
    "    # Get current station name\n",
    "    csta_name = cfile[0:3] # Take the first three letter abbreviation as the name\n",
    "    print('Processing ' + csta_name)\n",
    "    \n",
    "    # Import data to pandas dataframe\n",
    "    dat = ascii.read(cfile,header_start=c_column_line,data_start=c_header,delimiter=c_delimiter,exclude_names='N/A')\n",
    "    datain = pd.DataFrame(dat.as_array())\n",
    "    \n",
    "    # Make TIMESTAMP the index\n",
    "    datain['TIMESTAMP'] = datain['TIMESTAMP'].astype('datetime64[ns]')\n",
    "    datain = datain.set_index('TIMESTAMP')\n",
    "    \n",
    "    # Set time zone\n",
    "    datain.index = datain.index.tz_localize(tz_in)\n",
    "    \n",
    "    # Import header info\n",
    "    headerinfo = pd.read_csv(cfile,nrows=2,skiprows=1)\n",
    "    \n",
    "    # Convert to xray\n",
    "    ds = xr.Dataset.from_dataframe(datain)\n",
    "    \n",
    "    # Rename time\n",
    "    ds.rename({'TIMESTAMP':'time'},inplace=True)\n",
    "    \n",
    "    # Add new site dimension and make record\n",
    "    ds = xr.concat([ds],'site',data_vars='all')\n",
    "    #ds_site['site'] = csta_name\n",
    "\n",
    "    # Add Coords\n",
    "    print('need to get correct site location info, make these variables')\n",
    "    #c_LAT xr.DataArray(39.0,['site',0])\n",
    "    #ds = xr.concat({'LAT':('site',[39.0])})\n",
    "    ds.coords['LAT'] = 39.0\n",
    "    ds.coords['LON'] = -120.0\n",
    "    #ds.coords['sta_name'] = csta_name\n",
    "    \n",
    "    # Add variable attributes (units and sample period)\n",
    "    for cvar in ds.data_vars:\n",
    "        ds.get(cvar).attrs['unit']   = headerinfo.loc[0,[cvar]].values[0]\n",
    "        #ds.get(cvar).attrs['sample'] = headerinfo.loc[1,[cvar]].values[0]\n",
    "        \n",
    "    print(ds.dims)\n",
    "    ds_ALL.append(ds)\n",
    "    \n",
    "    # Export to netcdf\n",
    "    cfileout = os.path.join(dir_out,csta_name + '.nc')\n",
    "    ds.to_netcdf(cfileout,format='netcdf4') #,encoding={'AirTemp_Avg': {'dtype': 'int16', 'scale_factor': 0.1, '_FillValue': -9999}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
